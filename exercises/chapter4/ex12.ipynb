{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL/01Ktp9Uw6rHU3/N0KYU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nfilipas/handson-ml3/blob/main/exercises/chapter4/ex12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "6qBEnQDiynmi"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from copy import deepcopy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris(as_frame=True) # load dataset\n",
        "\n",
        "# get X and y\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "lwlFYTR1z9TK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_and_split_data(data, test_ratio, seed):\n",
        "    np.random.seed(seed)\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]"
      ],
      "metadata": {
        "id": "a3H_Ed7009KR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split among training, validation and test sets\n",
        "\n",
        "seed = 42\n",
        "\n",
        "X_train_val, X_test = shuffle_and_split_data(X, 0.2, seed)\n",
        "y_train_val, y_test = shuffle_and_split_data(y, 0.2, seed)\n",
        "\n",
        "X_train, X_val = shuffle_and_split_data(X_train_val, 0.2, seed)\n",
        "y_train, y_val = shuffle_and_split_data(y_train_val, 0.2, seed)"
      ],
      "metadata": {
        "id": "LKIYQVwx3YLC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class softmax_regressor:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.trained = False\n",
        "\n",
        "    def train(self, X, y, n_epochs, eta, seed):\n",
        "        m = len(X) # number of instances\n",
        "        n = len(X.columns) # number of features\n",
        "        K = len(np.unique(y)) # number of classes\n",
        "\n",
        "        # random initialization of matrix theta\n",
        "        np.random.seed(seed)\n",
        "        self.theta = np.random.randn(K, n+1)\n",
        "\n",
        "        # extend X matrix\n",
        "        X_ext = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
        "\n",
        "        # calculate y as a matrix\n",
        "        y_matrix = np.empty((K, m))\n",
        "        for c in range(m):\n",
        "            for k in range(K):\n",
        "                y_matrix[k, c] = y.iloc[c] == k\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "\n",
        "            # calculate matrix s\n",
        "            s = self.theta @ X_ext.T # s has classes on rows, number of instances on columns\n",
        "\n",
        "            # calculate matrix p_hat\n",
        "            p_hat = np.empty(s.shape)\n",
        "            for c in range(m):\n",
        "                den = 0\n",
        "                for k in range(K):\n",
        "                    den += np.exp(s[k, c])\n",
        "                for k in range(K):\n",
        "                    p_hat[k, c] = np.exp(s[k, c]) / den\n",
        "\n",
        "            # calculate gradient matrix\n",
        "            diff_matrix = p_hat - y_matrix\n",
        "\n",
        "            gradients = np.zeros(self.theta.shape)\n",
        "            for k in range(K):\n",
        "                for c in range(m):\n",
        "                    gradients[k, :] += diff_matrix[k, c] * X_ext[c, :]\n",
        "            gradients = 1/m*gradients\n",
        "\n",
        "            # make a step\n",
        "            self.theta -= eta*gradients\n",
        "\n",
        "        self.trained = True\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.trained:\n",
        "            raise ValueError(\"Classifier has not been trained yet.\")\n",
        "\n",
        "        m = len(X)\n",
        "        X_ext = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
        "        return np.argmax(self.theta @ X_ext.T, axis=0)\n"
      ],
      "metadata": {
        "id": "lhMLRdIw5cPH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs_tot = 1000\n",
        "eta = 0.1\n",
        "seed = 42\n",
        "accuracy_train_all = []\n",
        "accuracy_val_all = []\n",
        "best_accuracy_val = 0\n",
        "\n",
        "for n_epochs in range(n_epochs_tot):\n",
        "    softmax_clf = softmax_regressor()\n",
        "    softmax_clf.train(X_train, y_train, n_epochs=n_epochs, eta=eta, seed=seed)\n",
        "    y_train_pred = softmax_clf.predict(X_train)\n",
        "    accuracy_train = np.sum((y_train - y_train_pred) == 0) / len(y_train)\n",
        "    accuracy_train_all.append(accuracy_train)\n",
        "    y_val_pred = softmax_clf.predict(X_val)\n",
        "    accuracy_val = np.sum((y_val - y_val_pred) == 0) / len(y_val)\n",
        "    accuracy_val_all.append(accuracy_val)\n",
        "    if accuracy_val > best_accuracy_val:\n",
        "        best_accuracy_val = accuracy_val\n",
        "        best_model = deepcopy(softmax_clf)"
      ],
      "metadata": {
        "id": "LwqcaIEHv6_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(range(n_epochs_tot), accuracy_train_all, label=\"Training set\")\n",
        "plt.plot(range(n_epochs_tot), accuracy_val_all, label=\"Validation set\", alpha=0.7)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Early stopping\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A0bvFAVu6lDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_model.predict(X_test)\n",
        "accuracy_test = np.sum((y_test - y_test_pred) == 0) / len(y_test)\n",
        "print(accuracy_test)"
      ],
      "metadata": {
        "id": "0DCGbO0q9-dX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}